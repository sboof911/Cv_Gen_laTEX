{
    "en": [
        {
            "section": "Deep Learning",
            "projects": [
                {
                    "title": "Game Bot (Personal Project)",
                    "link": null,
                    "linkTool": null,
                    "used_tools": [
                        "Python",
                        "Sockets",
                        "Reinforcement Learning"
                    ],
                    "descriptions": [
                        "Created an interface that connects a custom Python bot to an online game using sockets for real-time communication.",
                        "Automated gameplay by integrating reinforcement learning models, enabling the bot to make decisions and play autonomously."
                    ]
                },
                {
                    "title": "Leaffliction",
                    "link": "https://github.com/sboof911/Leaffliction",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "PyTorch",
                        "ResNet-18",
                        "Transfer Learning",
                        "Image Augmentation"
                    ],
                    "descriptions": [
                        "Developed a plant disease detection model using transfer learning with ResNet-18.",
                        "Applied data augmentation (resizing, grayscale, blur) to improve model robustness.",
                        "Separated training and prediction into modular scripts for easy reuse."
                    ]
                },
                {
                    "title": "Fried Eggs",
                    "link": "https://github.com/sboof911/Fried-eggs",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Deep Learning",
                        "CNN",
                        "Instance Segmentation",
                        "Object Detection"
                    ],
                    "descriptions": [
                        "Labeled images with CVAT and prepared datasets for computer vision tasks.",
                        "Preprocessed and trained convolutional neural networks (CNNs) for object detection and segmentation.",
                        "Built a complete pipeline to predict and classify new images beyond the training set."
                    ]
                }
            ]
        },
        {
            "section": "Machine Learning",
            "projects": [
                {
                    "title": "Multilayer Perceptron",
                    "link": "https://github.com/sboof911/Multilayer-Perceptron",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "NumPy",
                        "Matplotlib",
                        "Neural Networks"
                    ],
                    "descriptions": [
                        "Implemented a feed-forward multilayer perceptron from scratch to classify breast cancer data.",
                        "Built training, evaluation, and visualization modules including accuracy and loss curves.",
                        "Designed a modular prediction pipeline to validate real test cases."
                    ]
                },
                {
                    "title": "Total-perspective-vortex",
                    "link": "https://github.com/sboof911/total-perspectivevortex",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Data Processing",
                        "EEG",
                        "Logistic Regression",
                        "MLP",
                        "Random Forest"
                    ],
                    "descriptions": [
                        "Preprocessed and visualized EEG brainwave data to prepare it for machine learning applications.",
                        "Built and compared multiple models, including Logistic Regression, MLP, and Random Forest, to evaluate prediction accuracy.",
                        "Developed a pipeline to predict user actions based on EEG signals, exploring applications in brain-computer interaction."
                    ]
                },
                {
                    "title": "Churn",
                    "link": "https://github.com/sboof911/churn",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Neural Networks",
                        "Dropout",
                        "Backpropagation"
                    ],
                    "descriptions": [
                        "Implemented a fully-connected neural network to predict customer churn.",
                        "Explored hidden layers, activation functions, backpropagation, and dropout.",
                        "Evaluated model performance on real-world datasets."
                    ]
                },
                {
                    "title": "MySpotify",
                    "link": "https://github.com/sboof911/MySpotify",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Pandas",
                        "Word2Vec",
                        "MLPClassifier",
                        "Alternating Least Squares (ALS)"
                    ],
                    "descriptions": [
                        "Built a recommendation engine that integrates multiple strategies: baseline, content-based, and collaborative filtering.",
                        "Implemented Word2Vec embeddings and MLP classifiers to model music similarity and user preferences.",
                        "Developed ALS-based collaborative filtering for personalized recommendations."
                    ]
                }
            ]
        },
        {
            "section": "NLP / Text Analysis",
            "projects": [
                {
                    "title": "Understanding Customer",
                    "link": "https://github.com/sboof911/Understanding-customer",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Jupyter Notebook",
                        "RNN",
                        "LSTM",
                        "Transformer",
                        "BERT",
                        "Falconsai intent_classification"
                    ],
                    "descriptions": [
                        "Designed deep learning experiments for intent classification using RNN, LSTM, and Transformer-based models.",
                        "Fine-tuned the Falconsai/intent_classification model on custom datasets to improve accuracy.",
                        "Compared preprocessing pipelines and architectures to evaluate model performance."
                    ]
                },
                {
                    "title": "Tweets",
                    "link": "https://github.com/sboof911/tweets",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Natural Language Processing",
                        "TF-IDF",
                        "Word2Vec"
                    ],
                    "descriptions": [
                        "Explored NLP techniques including bag-of-words, TF-IDF, stemming, lemmatization, and stopword removal.",
                        "Implemented similarity models with cosine distance and n-gram analysis.",
                        "Integrated word2vec embeddings to improve semantic understanding."
                    ]
                }
            ]
        },
        {
            "section": "Time Series & Data Analysis",
            "projects": [
                {
                    "title": "Uber",
                    "link": "https://github.com/sboof911/Uber",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Pandas",
                        "Time Series Analysis",
                        "ARIMA",
                        "Exponential Smoothing"
                    ],
                    "descriptions": [
                        "Performed time series analysis on Uber ride data to forecast demand.",
                        "Implemented Triple Exponential Smoothing (TES) and ARIMA models.",
                        "Engineered features such as ride counts by hour, day, and month."
                    ]
                },
                {
                    "title": "City Life",
                    "link": "https://github.com/sboof911/City-Life",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "GeoPandas",
                        "Clustering",
                        "Geospatial Analytics"
                    ],
                    "descriptions": [
                        "Conducted geospatial analysis on urban mobility datasets.",
                        "Applied clustering techniques to identify patterns in city ride distribution.",
                        "Built interactive maps to visualize results with GeoPandas."
                    ]
                }
            ]
        },
        {
            "section": "Games & Algorithm",
            "projects": [
                {
                    "title": "Gomoku",
                    "link": "https://github.com/sboof911/Gomoku",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "TypeScript",
                        "React",
                        "Minimax Algorithm",
                        "Alpha-Beta Pruning",
                        "Memoization"
                    ],
                    "descriptions": [
                        "Developed a complete Gomoku game with both backend (Python) and frontend (TypeScript/React).",
                        "Implemented an AI opponent using the Minimax algorithm with alpha-beta pruning and heuristics.",
                        "Optimized performance by introducing memorization to avoid redundant calculations."
                    ]
                }
            ]
        },
        {
            "section":"Software Projects",
            "projects": [
                {
                "title": "Minishell",
                "link": "https://github.com/sboof911/minishell",
                "linkTool": "Github",
                "used_tools": [
                    "C",
                    "Unix System Calls",
                    "Parsing & Tokenization",
                    "Signal Handling"
                ],
                "descriptions": [
                    "Recreated a simplified Bash-like shell from scratch in C.",
                    "Implemented core functionalities: built-in commands (echo, cd, pwd, export, unset, env, exit), environment variable expansion."
                 ]
                },
                {
                    "title": "Ft_services",
                    "link": "https://github.com/sboof911/ft_services",
                    "linkTool": "GitHub",
                    "used_tools": [
                    "Docker",
                    "Kubernetes",
                    "Nginx",
                    "MySQL",
                    "Grafana",
                    "InfluxDB",
                    "WordPress",
                    "phpMyAdmin"
                    ],
                    "descriptions": [
                    "Containerized and deployed multiple services (Nginx, MySQL, WordPress, Grafana, InfluxDB, phpMyAdmin).",
                    "Used Docker Compose and Kubernetes to orchestrate a multi-service infrastructure.",
                    "Automated service deployment with custom shell scripts."
                    ]
                },
                {
                    "title": "Webserv",
                    "link": "https://github.com/sboof911/webserv",
                    "linkTool": "GitHub",
                    "used_tools": [
                    "C++",
                    "HTTP/1.1",
                    "Sockets"
                    ],
                    "descriptions": [
                    "Developed a fully functional HTTP server in C++ supporting HTTP/1.1.",
                    "Handled socket programming, request parsing, and response generation.",
                    "Supported CGI execution and tested compatibility with real browsers."
                    ]
                },
                {
                    "title": "Ft_transcendence",
                    "link": "https://github.com/sboof911/ft_transcendence",
                    "linkTool": "GitHub",
                    "used_tools": [
                    "TypeScript",
                    "NestJS",
                    "React",
                    "PostgreSQL",
                    "WebSockets",
                    "Docker"
                    ],
                    "descriptions": [
                    "Developed a full-stack web application with authentication, chat, and multiplayer Pong game.",
                    "Backend built with NestJS and PostgreSQL, frontend with React.",
                    "Integrated WebSockets for real-time interactions and containerized with Docker."
                    ]
                }
            ]
        }
    ],
    "fr": [
        {
            "section": "Deep Learning",
            "projects": [
                {
                    "title": "Game Bot (Personal Project)",
                    "link": null,
                    "linkTool": null,
                    "used_tools": [
                        "Python",
                        "Sockets",
                        "Reinforcement Learning"
                    ],
                    "descriptions": [
                        "Créé une interface qui connecte un bot Python personnalisé à un jeu en ligne via des sockets pour une communication en temps réel.",
                        "Automatisation du jeu en intégrant des modèles d'apprentissage par renforcement, permettant au bot de prendre des décisions et de jouer de façon autonome."
                    ]
                },
                {
                    "title": "Leaffliction",
                    "link": "https://github.com/sboof911/Leaffliction",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "PyTorch",
                        "ResNet-18",
                        "Transfer Learning",
                        "Image Augmentation"
                    ],
                    "descriptions": [
                        "Développé un modèle de détection de maladies des plantes en utilisant le transfert d'apprentissage avec ResNet-18.",
                        "Appliqué l'augmentation de données (redimensionnement, niveaux de gris, flou) pour améliorer la robustesse du modèle.",
                        "Séparé l'entraînement et la prédiction dans des scripts modulaires pour une réutilisation facile."
                    ]
                },
                {
                    "title": "Fried Eggs",
                    "link": "https://github.com/sboof911/Fried-eggs",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Deep Learning",
                        "CNN",
                        "Instance Segmentation",
                        "Object Detection"
                    ],
                    "descriptions": [
                        "Annoté des images avec CVAT et préparé des jeux de données pour des tâches de vision par ordinateur.",
                        "Prétraité et entraîné des réseaux de neurones convolutifs (CNN) pour la détection et la segmentation d'objets.",
                        "Construit un pipeline complet pour prédire et classifier de nouvelles images au-delà du jeu d'entraînement."
                    ]
                }
            ]
        },
        {
            "section": "Machine Learning",
            "projects": [
                {
                    "title": "Multilayer Perceptron",
                    "link": "https://github.com/sboof911/Multilayer-Perceptron",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "NumPy",
                        "Matplotlib",
                        "Neural Networks"
                    ],
                    "descriptions": [
                        "Implémenté un perceptron multicouche à propagation avant depuis zéro pour classifier des données sur le cancer du sein.",
                        "Créé des modules d'entraînement, d'évaluation et de visualisation incluant les courbes de précision et de perte.",
                        "Conçu un pipeline de prédiction modulaire pour valider des cas de test réels."
                    ]
                },
                {
                    "title": "Total-perspective-vortex",
                    "link": "https://github.com/sboof911/total-perspectivevortex",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Data Processing",
                        "EEG",
                        "Logistic Regression",
                        "MLP",
                        "Random Forest"
                    ],
                    "descriptions": [
                        "Prétraité et visualisé des données EEG pour les préparer à des applications d'apprentissage automatique.",
                        "Construit et comparé plusieurs modèles, dont la régression logistique, MLP et Random Forest, pour évaluer la précision des prédictions.",
                        "Développé un pipeline pour prédire les actions des utilisateurs à partir des signaux EEG, explorant des applications en interaction cerveau-machine."
                    ]
                },
                {
                    "title": "Churn",
                    "link": "https://github.com/sboof911/churn",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Neural Networks",
                        "Dropout",
                        "Backpropagation"
                    ],
                    "descriptions": [
                        "Implémenté un réseau de neurones entièrement connecté pour prédire le churn des clients.",
                        "Exploré les couches cachées, les fonctions d'activation, la rétropropagation et le dropout.",
                        "Évalué la performance du modèle sur des jeux de données réels."
                    ]
                },
                {
                    "title": "MySpotify",
                    "link": "https://github.com/sboof911/MySpotify",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Pandas",
                        "Word2Vec",
                        "MLPClassifier",
                        "Alternating Least Squares (ALS)"
                    ],
                    "descriptions": [
                        "Construit un moteur de recommandation intégrant plusieurs stratégies : baseline, filtrage par contenu et filtrage collaboratif.",
                        "Implémenté des embeddings Word2Vec et des classificateurs MLP pour modéliser la similarité musicale et les préférences des utilisateurs.",
                        "Développé un filtrage collaboratif basé sur ALS pour des recommandations personnalisées."
                    ]
                }
            ]
        },
        {
            "section": "NLP / Text Analysis",
            "projects": [
                {
                    "title": "Understanding Customer",
                    "link": "https://github.com/sboof911/Understanding-customer",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Jupyter Notebook",
                        "RNN",
                        "LSTM",
                        "Transformer",
                        "BERT",
                        "Falconsai intent_classification"
                    ],
                    "descriptions": [
                        "Conçu des expériences d'apprentissage profond pour la classification d'intentions avec des modèles RNN, LSTM et Transformer.",
                        "Ajusté le modèle Falconsai/intent_classification sur des jeux de données personnalisés pour améliorer la précision.",
                        "Comparé les pipelines de prétraitement et les architectures pour évaluer la performance des modèles."
                    ]
                },
                {
                    "title": "Tweets",
                    "link": "https://github.com/sboof911/tweets",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Natural Language Processing",
                        "TF-IDF",
                        "Word2Vec"
                    ],
                    "descriptions": [
                        "Exploré des techniques NLP incluant bag-of-words, TF-IDF, stemming, lemmatisation et suppression des stopwords.",
                        "Implémenté des modèles de similarité avec la distance cosinus et l'analyse n-gram.",
                        "Intégré des embeddings word2vec pour améliorer la compréhension sémantique."
                    ]
                }
            ]
        },
        {
            "section": "Time Series & Data Analysis",
            "projects": [
                {
                    "title": "Uber",
                    "link": "https://github.com/sboof911/Uber",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "Pandas",
                        "Time Series Analysis",
                        "ARIMA",
                        "Exponential Smoothing"
                    ],
                    "descriptions": [
                        "Réalisé une analyse de séries temporelles sur les données de trajets Uber pour prévoir la demande.",
                        "Implémenté des modèles TES (Triple Exponential Smoothing) et ARIMA.",
                        "Créé des variables telles que le nombre de trajets par heure, jour et mois."
                    ]
                },
                {
                    "title": "City Life",
                    "link": "https://github.com/sboof911/City-Life",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "GeoPandas",
                        "Clustering",
                        "Geospatial Analytics"
                    ],
                    "descriptions": [
                        "Réalisé une analyse géospatiale sur des jeux de données de mobilité urbaine.",
                        "Appliqué des techniques de clustering pour identifier des motifs dans la distribution des trajets en ville.",
                        "Construit des cartes interactives pour visualiser les résultats avec GeoPandas."
                    ]
                }
            ]
        },
        {
            "section": "Games & Algorithm",
            "projects": [
                {
                    "title": "Gomoku",
                    "link": "https://github.com/sboof911/Gomoku",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Python",
                        "TypeScript",
                        "React",
                        "Minimax Algorithm",
                        "Alpha-Beta Pruning",
                        "Memoization"
                    ],
                    "descriptions": [
                        "Développé un jeu complet de Gomoku avec backend (Python) et frontend (TypeScript/React).",
                        "Implémenté un adversaire IA utilisant l'algorithme Minimax avec élagage alpha-bêta et heuristiques.",
                        "Optimisé les performances en introduisant la mémorisation pour éviter les calculs redondants."
                    ]
                }
            ]
        },
        {
            "section": "Software Projects",
            "projects": [
                {
                    "title": "Minishell",
                    "link": "https://github.com/sboof911/minishell",
                    "linkTool": "Github",
                    "used_tools": [
                        "C",
                        "Unix System Calls",
                        "Parsing & Tokenization",
                        "Signal Handling"
                    ],
                    "descriptions": [
                        "Recréé un shell simplifié de type Bash en C depuis zéro.",
                        "Implémenté les fonctionnalités principales : commandes intégrées (echo, cd, pwd, export, unset, env, exit), expansion des variables d'environnement."
                    ]
                },
                {
                    "title": "Ft_services",
                    "link": "https://github.com/sboof911/ft_services",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "Docker",
                        "Kubernetes",
                        "Nginx",
                        "MySQL",
                        "Grafana",
                        "InfluxDB",
                        "WordPress",
                        "phpMyAdmin"
                    ],
                    "descriptions": [
                        "Containerisé et déployé plusieurs services (Nginx, MySQL, WordPress, Grafana, InfluxDB, phpMyAdmin).",
                        "Utilisé Docker Compose et Kubernetes pour orchestrer une infrastructure multi-services.",
                        "Automatisé le déploiement des services avec des scripts shell personnalisés."
                    ]
                },
                {
                    "title": "Webserv",
                    "link": "https://github.com/sboof911/webserv",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "C++",
                        "HTTP/1.1",
                        "Sockets"
                    ],
                    "descriptions": [
                        "Développé un serveur HTTP entièrement fonctionnel en C++ supportant HTTP/1.1.",
                        "Géré la programmation des sockets, le parsing des requêtes et la génération des réponses.",
                        "Supporté l'exécution CGI et testé la compatibilité avec de vrais navigateurs."
                    ]
                },
                {
                    "title": "Ft_transcendence",
                    "link": "https://github.com/sboof911/ft_transcendence",
                    "linkTool": "GitHub",
                    "used_tools": [
                        "TypeScript",
                        "NestJS",
                        "React",
                        "PostgreSQL",
                        "WebSockets",
                        "Docker"
                    ],
                    "descriptions": [
                        "Développé une application web full-stack avec authentification, chat et jeu Pong multijoueur.",
                        "Backend construit avec NestJS et PostgreSQL, frontend avec React.",
                        "Intégré WebSockets pour les interactions en temps réel et containerisé avec Docker."
                    ]
                }
            ]
        }
    ]
}